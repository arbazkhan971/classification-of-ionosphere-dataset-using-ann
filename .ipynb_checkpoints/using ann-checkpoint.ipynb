{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.utils import np_utils \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import math\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"ionosphere.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>-0.00592</td>\n",
       "      <td>-0.09924</td>\n",
       "      <td>-0.11949</td>\n",
       "      <td>-0.00763</td>\n",
       "      <td>-0.11824</td>\n",
       "      <td>0.14706</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01535</td>\n",
       "      <td>-0.03240</td>\n",
       "      <td>0.09223</td>\n",
       "      <td>-0.07859</td>\n",
       "      <td>0.00732</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00039</td>\n",
       "      <td>0.12011</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97588</td>\n",
       "      <td>-0.10602</td>\n",
       "      <td>0.94601</td>\n",
       "      <td>-0.20800</td>\n",
       "      <td>0.92806</td>\n",
       "      <td>-0.28350</td>\n",
       "      <td>0.85996</td>\n",
       "      <td>-0.27342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.81634</td>\n",
       "      <td>0.13659</td>\n",
       "      <td>-0.82510</td>\n",
       "      <td>0.04606</td>\n",
       "      <td>-0.82395</td>\n",
       "      <td>-0.04262</td>\n",
       "      <td>-0.81318</td>\n",
       "      <td>-0.13832</td>\n",
       "      <td>-0.80975</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96355</td>\n",
       "      <td>-0.07198</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.21313</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.36174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65440</td>\n",
       "      <td>0.57577</td>\n",
       "      <td>-0.69712</td>\n",
       "      <td>0.25435</td>\n",
       "      <td>-0.63919</td>\n",
       "      <td>0.45114</td>\n",
       "      <td>-0.72779</td>\n",
       "      <td>0.38895</td>\n",
       "      <td>-0.73420</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01864</td>\n",
       "      <td>-0.08459</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>-0.26810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01326</td>\n",
       "      <td>0.20645</td>\n",
       "      <td>-0.02294</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16595</td>\n",
       "      <td>0.24086</td>\n",
       "      <td>-0.08208</td>\n",
       "      <td>0.38065</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "5         1         0   0.02337  -0.00592  -0.09924  -0.11949  -0.00763   \n",
       "6         1         0   0.97588  -0.10602   0.94601  -0.20800   0.92806   \n",
       "7         0         0   0.00000   0.00000   0.00000   0.00000   1.00000   \n",
       "8         1         0   0.96355  -0.07198   1.00000  -0.14333   1.00000   \n",
       "9         1         0  -0.01864  -0.08459   0.00000   0.00000   0.00000   \n",
       "\n",
       "   feature8  feature9  feature10  ...    feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...     -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...     -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...     -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...      0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...     -0.65158    0.13290   -0.53206   \n",
       "5  -0.11824   0.14706    0.06637  ...     -0.01535   -0.03240    0.09223   \n",
       "6  -0.28350   0.85996   -0.27342  ...     -0.81634    0.13659   -0.82510   \n",
       "7  -1.00000   0.00000    0.00000  ...      1.00000    1.00000    1.00000   \n",
       "8  -0.21313   1.00000   -0.36174  ...     -0.65440    0.57577   -0.69712   \n",
       "9   0.00000   0.11470   -0.26810  ...     -0.01326    0.20645   -0.02294   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "5   -0.07859    0.00732    0.00000    0.00000   -0.00039    0.12011      b  \n",
       "6    0.04606   -0.82395   -0.04262   -0.81318   -0.13832   -0.80975      g  \n",
       "7    0.00000    0.00000    1.00000    1.00000    0.00000    0.00000      b  \n",
       "8    0.25435   -0.63919    0.45114   -0.72779    0.38895   -0.73420      g  \n",
       "9    0.00000    0.00000    0.16595    0.24086   -0.08208    0.38065      b  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder() \n",
    "encoder.fit(y) \n",
    "Y= encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "def baseline_model(): \n",
    "    # create model \n",
    "    model = Sequential() \n",
    "    model.add(Dense(34, input_dim=34, init= \"normal\" , activation= \"relu\" )) \n",
    "    model.add(Dense(16, init= \"normal\" , activation= \"relu\" ))\n",
    "    model.add(Dense(1, init= \"normal\" , activation= \"sigmoid\" )) \n",
    "    # Compile model\n",
    "     \n",
    "    learning_rate = 0.1 \n",
    "    decay_rate = learning_rate / epochs \n",
    "    momentum = 0.8 \n",
    "    sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss= \"binary_crossentropy\" , optimizer=sgd, metrics=[ \"accuracy\" ]) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=epochs, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6721 - acc: 0.6317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6740 - acc: 0.6159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 0.6770 - acc: 0.6476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6725 - acc: 0.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6713 - acc: 0.6254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6737 - acc: 0.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 0.6758 - acc: 0.5931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 0.6733 - acc: 0.6372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 0.6774 - acc: 0.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 0.6799 - acc: 0.5899\n",
      "Larger: 64.11% (0.57%)\n"
     ]
    }
   ],
   "source": [
    "estimators = [] \n",
    "estimators.append(( \"standardize\" , StandardScaler())) \n",
    "estimators.append(( \"mlp\" , KerasClassifier(build_fn=baseline_model, nb_epoch=epochs, batch_size=28, verbose=2))) \n",
    "pipeline = Pipeline(estimators) \n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed) \n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold) \n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6936 - acc: 0.4723 - val_loss: 0.6958 - val_acc: 0.1293\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5447 - val_loss: 0.6885 - val_acc: 0.6724\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5362 - val_loss: 0.6779 - val_acc: 0.7586\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6830 - acc: 0.6638 - val_loss: 0.6706 - val_acc: 0.6810\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6642 - acc: 0.7404 - val_loss: 0.6044 - val_acc: 0.7241\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6125 - acc: 0.7404 - val_loss: 0.4885 - val_acc: 0.8103\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.5584 - acc: 0.7872 - val_loss: 0.5251 - val_acc: 0.7586\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.4568 - acc: 0.8383 - val_loss: 0.2999 - val_acc: 0.9483\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.3851 - acc: 0.8596 - val_loss: 0.2008 - val_acc: 0.9655\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.2857 - acc: 0.8766 - val_loss: 0.1338 - val_acc: 0.9655\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.2187 - acc: 0.9277 - val_loss: 0.1473 - val_acc: 0.9655\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.2229 - acc: 0.9149 - val_loss: 0.2632 - val_acc: 0.9052\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.2009 - acc: 0.9234 - val_loss: 0.3982 - val_acc: 0.7759\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.2403 - acc: 0.9021 - val_loss: 0.1082 - val_acc: 0.9914\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.1569 - acc: 0.9362 - val_loss: 0.1784 - val_acc: 0.9483\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.1614 - acc: 0.9319 - val_loss: 0.1820 - val_acc: 0.9483\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.1877 - acc: 0.9362 - val_loss: 0.1591 - val_acc: 0.9655\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.1231 - acc: 0.9404 - val_loss: 0.0703 - val_acc: 0.9828\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.1238 - acc: 0.9702 - val_loss: 0.0541 - val_acc: 0.9828\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0982 - acc: 0.9489 - val_loss: 0.0547 - val_acc: 0.9914\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.1139 - acc: 0.9660 - val_loss: 0.0589 - val_acc: 0.9914\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0993 - acc: 0.9702 - val_loss: 0.0786 - val_acc: 0.9914\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0772 - acc: 0.9787 - val_loss: 0.0448 - val_acc: 0.9914\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0930 - acc: 0.9745 - val_loss: 0.0598 - val_acc: 0.9914\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0635 - acc: 0.9787 - val_loss: 0.0694 - val_acc: 0.9914\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0627 - acc: 0.9872 - val_loss: 0.1059 - val_acc: 0.9741\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0556 - acc: 0.9872 - val_loss: 0.0425 - val_acc: 0.9914\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0649 - acc: 0.9660 - val_loss: 0.0982 - val_acc: 0.9828\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0575 - acc: 0.9830 - val_loss: 0.0611 - val_acc: 0.9914\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0517 - acc: 0.9915 - val_loss: 0.0461 - val_acc: 0.9914\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0531 - acc: 0.9872 - val_loss: 0.0666 - val_acc: 0.9828\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0402 - acc: 0.9872 - val_loss: 0.0561 - val_acc: 0.9914\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0366 - acc: 0.9915 - val_loss: 0.0574 - val_acc: 0.9914\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0335 - acc: 0.9957 - val_loss: 0.0475 - val_acc: 0.9914\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0429 - acc: 0.9830 - val_loss: 0.0433 - val_acc: 0.9914\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0601 - acc: 0.9872 - val_loss: 0.0524 - val_acc: 0.9914\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0342 - acc: 0.9957 - val_loss: 0.0508 - val_acc: 0.9914\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0301 - acc: 0.9957 - val_loss: 0.1003 - val_acc: 0.9741\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0365 - acc: 0.9957 - val_loss: 0.0459 - val_acc: 0.9914\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0426 - acc: 0.9915 - val_loss: 0.0514 - val_acc: 0.9914\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0346 - acc: 0.9915 - val_loss: 0.1004 - val_acc: 0.9741\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0324 - acc: 0.9915 - val_loss: 0.0487 - val_acc: 0.9914\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0441 - acc: 0.9830 - val_loss: 0.1114 - val_acc: 0.9569\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0313 - acc: 0.9915 - val_loss: 0.0435 - val_acc: 0.9914\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0264 - acc: 0.9957 - val_loss: 0.1177 - val_acc: 0.9310\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0509 - acc: 0.9872 - val_loss: 0.0475 - val_acc: 0.9914\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0300 - acc: 0.9957 - val_loss: 0.0515 - val_acc: 0.9828\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0298 - acc: 0.9957 - val_loss: 0.0573 - val_acc: 0.9828\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0278 - acc: 0.9957 - val_loss: 0.0596 - val_acc: 0.9828\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0231 - acc: 0.9957 - val_loss: 0.0675 - val_acc: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f96c1a9860>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(34, input_dim=34, init= \"normal\" , activation= \"relu\" )) \n",
    "model.add(Dense(16, init= \"normal\" , activation= \"relu\" ))\n",
    "model.add(Dense(1, init= \"normal\" , activation= \"sigmoid\" )) \n",
    "# Compile model     \n",
    "learning_rate = 0.1 \n",
    "decay_rate = learning_rate / epochs \n",
    "momentum = 0.8 \n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer=sgd, metrics=[ \"accuracy\" ])\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=epochs, batch_size=28, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch): \n",
    "    initial_lrate = 0.1 \n",
    "    drop = 0.5 \n",
    "    epochs_drop = 5.0 \n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop)) \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(34, input_dim=34, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(7, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \"\"\"\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"normal\", activation=\"relu\")`\n",
      "  import sys\n",
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(34, input_dim=34, init= \"normal\" , activation= \"relu\" ))\n",
    "model.add(Dense(25, init= \"normal\" , activation= \"relu\" ))\n",
    "model.add(Dense(25, init= \"normal\" , activation= \"relu\" ))\n",
    "model.add(Dense(7, init= \"normal\" , activation= \"relu\" ))\n",
    "model.add(Dense(3, init= \"normal\" , activation= \"relu\" ))\n",
    "model.add(Dense(2, init= \"normal\" , activation= \"relu\" ))\n",
    "\n",
    "model.add(Dense(1, init= \"normal\" , activation= \"sigmoid\" ))\n",
    "sgd = SGD(lr=0.00, momentum=0.95, decay=0.0, nesterov=False) \n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer=sgd, metrics=[ \"accuracy\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arbaz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.8160 - acc: 0.5702 - val_loss: 0.6463 - val_acc: 0.9224\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.8337 - acc: 0.5106 - val_loss: 0.7903 - val_acc: 0.0776\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.7678 - acc: 0.5319 - val_loss: 1.1144 - val_acc: 0.0776\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.8909 - acc: 0.5277 - val_loss: 3.4896 - val_acc: 0.0776\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.7835 - acc: 0.5191 - val_loss: 0.9311 - val_acc: 0.0776\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.7638 - acc: 0.4298 - val_loss: 0.7763 - val_acc: 0.0776\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.7342 - acc: 0.5532 - val_loss: 1.0482 - val_acc: 0.0776\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.7614 - acc: 0.4638 - val_loss: 0.4176 - val_acc: 0.9224\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.7289 - acc: 0.4936 - val_loss: 0.7426 - val_acc: 0.0776\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.7176 - acc: 0.4426 - val_loss: 0.9720 - val_acc: 0.0776\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.7187 - acc: 0.4553 - val_loss: 1.0415 - val_acc: 0.0776\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.7222 - acc: 0.4894 - val_loss: 0.5435 - val_acc: 0.9224\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.7346 - acc: 0.4681 - val_loss: 0.4489 - val_acc: 0.9224\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.7211 - acc: 0.5234 - val_loss: 0.5571 - val_acc: 0.9224\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.7078 - acc: 0.4638 - val_loss: 0.6809 - val_acc: 0.9224\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.7058 - acc: 0.5277 - val_loss: 0.7499 - val_acc: 0.0776\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6991 - acc: 0.5362 - val_loss: 0.6421 - val_acc: 0.9224\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.7040 - acc: 0.5021 - val_loss: 0.5613 - val_acc: 0.9224\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.7199 - acc: 0.4936 - val_loss: 0.6634 - val_acc: 0.9224\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.7042 - acc: 0.4468 - val_loss: 0.6893 - val_acc: 0.9224\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.7094 - acc: 0.4766 - val_loss: 0.6739 - val_acc: 0.9224\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.7025 - acc: 0.5106 - val_loss: 0.6325 - val_acc: 0.9224\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.7023 - acc: 0.4426 - val_loss: 0.6306 - val_acc: 0.9224\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.7130 - acc: 0.4596 - val_loss: 0.5814 - val_acc: 0.9224\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6984 - acc: 0.5234 - val_loss: 0.7263 - val_acc: 0.0776\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6982 - acc: 0.4809 - val_loss: 0.6922 - val_acc: 0.9224\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6978 - acc: 0.4723 - val_loss: 0.7072 - val_acc: 0.0776\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6978 - acc: 0.4681 - val_loss: 0.7205 - val_acc: 0.0776\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6982 - acc: 0.4511 - val_loss: 0.7415 - val_acc: 0.0776\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6970 - acc: 0.4894 - val_loss: 0.6936 - val_acc: 0.0776\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6961 - acc: 0.4468 - val_loss: 0.6928 - val_acc: 0.9224\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6962 - acc: 0.4468 - val_loss: 0.6784 - val_acc: 0.9224\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6981 - acc: 0.4468 - val_loss: 0.6937 - val_acc: 0.0776\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6964 - acc: 0.5021 - val_loss: 0.7220 - val_acc: 0.0776\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6969 - acc: 0.4979 - val_loss: 0.6948 - val_acc: 0.0776\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6947 - acc: 0.5106 - val_loss: 0.6860 - val_acc: 0.9224\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6941 - acc: 0.4638 - val_loss: 0.6836 - val_acc: 0.9224\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6944 - acc: 0.4766 - val_loss: 0.6912 - val_acc: 0.9224\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6945 - acc: 0.4213 - val_loss: 0.6764 - val_acc: 0.9224\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4340 - val_loss: 0.6799 - val_acc: 0.9224\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4553 - val_loss: 0.6797 - val_acc: 0.9224\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5021 - val_loss: 0.6840 - val_acc: 0.9224\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4596 - val_loss: 0.6889 - val_acc: 0.9224\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6938 - acc: 0.4340 - val_loss: 0.6871 - val_acc: 0.9224\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5021 - val_loss: 0.6895 - val_acc: 0.9224\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5021 - val_loss: 0.6887 - val_acc: 0.9224\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5021 - val_loss: 0.6884 - val_acc: 0.9224\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5021 - val_loss: 0.6881 - val_acc: 0.9224\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6935 - acc: 0.4766 - val_loss: 0.6893 - val_acc: 0.9224\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5021 - val_loss: 0.6891 - val_acc: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f97049eeb8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning schedule callback \n",
    "lrate = LearningRateScheduler(step_decay) \n",
    "callbacks_list = [lrate] \n",
    "# Fit the model \n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=50, batch_size=1, callbacks=callbacks_list, verbose=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
